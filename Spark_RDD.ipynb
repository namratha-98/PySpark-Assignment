{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create RDDs in three different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Test RDD Examples').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Paralleize\n",
    "rdd_par=spark.sparkContext.parallelize([\"Hello World\", \"It's a wonderful day\", \"Goodbye\"])\n",
    "type(rdd_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using transformations\n",
    "rdd_trans=rdd_par.filter(lambda word:word.startswith('H'))\n",
    "#rdd_trans.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using data sources\n",
    "rdd_ds=spark.sparkContext.textFile('D:\\LoremIpsum.txt')\n",
    "type(rdd_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Read a text file and count the number of words in the file using RDD operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd=rdd_ds.flatMap(lambda word:word.split(' '))\n",
    "freq_words=word_rdd.map(lambda word:(word,1))\n",
    "freq_words.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a program to find the word frequency in a given file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lorem', 19),\n",
       " ('Ipsum', 15),\n",
       " ('is', 8),\n",
       " ('dummy', 2),\n",
       " ('of', 26),\n",
       " ('printing', 1),\n",
       " ('typesetting', 1),\n",
       " (\"industry's\", 1),\n",
       " ('ever', 1),\n",
       " ('1500s,', 1),\n",
       " ('when', 1),\n",
       " ('an', 1),\n",
       " ('unknown', 1),\n",
       " ('took', 1),\n",
       " ('galley', 1),\n",
       " ('type', 2),\n",
       " ('make', 1),\n",
       " ('book.', 1),\n",
       " ('It', 5),\n",
       " ('only', 1),\n",
       " ('but', 2),\n",
       " ('into', 1),\n",
       " ('typesetting,', 1),\n",
       " ('remaining', 1),\n",
       " ('essentially', 1),\n",
       " ('was', 1),\n",
       " ('in', 15),\n",
       " ('1960s', 1),\n",
       " ('passages,', 1),\n",
       " ('more', 3),\n",
       " ('desktop', 1),\n",
       " ('like', 1),\n",
       " ('Aldus', 1),\n",
       " ('PageMaker', 1),\n",
       " ('versions', 3),\n",
       " ('classical', 4),\n",
       " ('Latin', 7),\n",
       " ('45', 4),\n",
       " ('BC,', 2),\n",
       " ('making', 3),\n",
       " ('years', 2),\n",
       " ('at', 2),\n",
       " ('Hampden-Sydney', 2),\n",
       " ('College', 2),\n",
       " ('looked', 2),\n",
       " ('literature,', 2),\n",
       " ('undoubtable', 2),\n",
       " ('sections', 2),\n",
       " ('Finibus', 4),\n",
       " ('Bonorum', 4),\n",
       " ('Malorum\"', 4),\n",
       " ('(The', 2),\n",
       " ('Extremes', 2),\n",
       " ('Good', 2),\n",
       " ('Evil)', 2),\n",
       " ('Cicero,', 2),\n",
       " ('book', 2),\n",
       " ('treatise', 2),\n",
       " ('very', 2),\n",
       " ('during', 2),\n",
       " ('Renaissance.', 2),\n",
       " ('The', 5),\n",
       " ('line', 4),\n",
       " ('Ipsum,', 3),\n",
       " ('ipsum', 2),\n",
       " ('', 2),\n",
       " ('chunk', 2),\n",
       " ('used', 2),\n",
       " ('below', 2),\n",
       " ('interested.', 2),\n",
       " ('are', 4),\n",
       " ('form,', 3),\n",
       " ('English', 2),\n",
       " ('Rackham.', 2),\n",
       " ('passages', 1),\n",
       " ('have', 1),\n",
       " ('alteration', 1),\n",
       " ('injected', 2),\n",
       " ('look', 1),\n",
       " ('even', 1),\n",
       " ('believable.', 1),\n",
       " ('use', 1),\n",
       " ('sure', 1),\n",
       " ('there', 1),\n",
       " ('anything', 1),\n",
       " ('embarrassing', 1),\n",
       " ('hidden', 1),\n",
       " ('middle', 1),\n",
       " ('generators', 1),\n",
       " ('repeat', 1),\n",
       " ('as', 1),\n",
       " ('necessary,', 1),\n",
       " ('this', 1),\n",
       " ('true', 1),\n",
       " ('uses', 1),\n",
       " ('dictionary', 1),\n",
       " ('handful', 1),\n",
       " ('model', 1),\n",
       " ('generate', 1),\n",
       " ('looks', 1),\n",
       " ('generated', 1),\n",
       " ('always', 1),\n",
       " ('free', 1),\n",
       " ('repetition,', 1),\n",
       " ('non-characteristic', 1),\n",
       " ('etc.', 1),\n",
       " ('simply', 3),\n",
       " ('text', 2),\n",
       " ('the', 28),\n",
       " ('and', 11),\n",
       " ('industry.', 1),\n",
       " ('has', 4),\n",
       " ('been', 1),\n",
       " ('standard', 3),\n",
       " ('since', 3),\n",
       " ('printer', 1),\n",
       " ('a', 15),\n",
       " ('scrambled', 1),\n",
       " ('it', 3),\n",
       " ('to', 7),\n",
       " ('specimen', 1),\n",
       " ('survived', 1),\n",
       " ('not', 3),\n",
       " ('five', 1),\n",
       " ('centuries,', 1),\n",
       " ('also', 3),\n",
       " ('leap', 1),\n",
       " ('electronic', 1),\n",
       " ('unchanged.', 1),\n",
       " ('popularised', 1),\n",
       " ('with', 3),\n",
       " ('release', 1),\n",
       " ('Letraset', 1),\n",
       " ('sheets', 1),\n",
       " ('containing', 1),\n",
       " ('recently', 1),\n",
       " ('publishing', 1),\n",
       " ('software', 1),\n",
       " ('including', 1),\n",
       " ('Ipsum.', 1),\n",
       " ('Contrary', 2),\n",
       " ('popular', 4),\n",
       " ('belief,', 2),\n",
       " ('random', 2),\n",
       " ('text.', 3),\n",
       " ('roots', 2),\n",
       " ('piece', 2),\n",
       " ('literature', 2),\n",
       " ('from', 13),\n",
       " ('over', 3),\n",
       " ('2000', 2),\n",
       " ('old.', 2),\n",
       " ('Richard', 2),\n",
       " ('McClintock,', 2),\n",
       " ('professor', 2),\n",
       " ('Virginia,', 2),\n",
       " ('up', 2),\n",
       " ('one', 2),\n",
       " ('obscure', 2),\n",
       " ('words,', 3),\n",
       " ('consectetur,', 2),\n",
       " ('passage,', 2),\n",
       " ('going', 3),\n",
       " ('through', 2),\n",
       " ('cites', 2),\n",
       " ('word', 2),\n",
       " ('discovered', 2),\n",
       " ('source.', 2),\n",
       " ('comes', 4),\n",
       " ('1.10.32', 4),\n",
       " ('1.10.33', 4),\n",
       " ('\"de', 4),\n",
       " ('et', 4),\n",
       " ('by', 9),\n",
       " ('written', 2),\n",
       " ('BC.', 2),\n",
       " ('This', 2),\n",
       " ('on', 4),\n",
       " ('theory', 2),\n",
       " ('ethics,', 2),\n",
       " ('first', 3),\n",
       " ('\"Lorem', 2),\n",
       " ('dolor', 2),\n",
       " ('sit', 2),\n",
       " ('amet..\",', 2),\n",
       " ('section', 2),\n",
       " ('1.10.32.', 2),\n",
       " ('1500s', 2),\n",
       " ('reproduced', 4),\n",
       " ('for', 2),\n",
       " ('those', 2),\n",
       " ('Sections', 2),\n",
       " ('Cicero', 2),\n",
       " ('their', 2),\n",
       " ('exact', 2),\n",
       " ('original', 2),\n",
       " ('accompanied', 2),\n",
       " ('1914', 2),\n",
       " ('translation', 2),\n",
       " ('H.', 2),\n",
       " ('There', 1),\n",
       " ('many', 1),\n",
       " ('variations', 1),\n",
       " ('available,', 1),\n",
       " ('majority', 1),\n",
       " ('suffered', 1),\n",
       " ('some', 1),\n",
       " ('humour,', 2),\n",
       " ('or', 2),\n",
       " ('randomised', 1),\n",
       " ('words', 2),\n",
       " ('which', 2),\n",
       " (\"don't\", 1),\n",
       " ('slightly', 1),\n",
       " ('If', 1),\n",
       " ('you', 2),\n",
       " ('passage', 1),\n",
       " ('need', 1),\n",
       " ('be', 1),\n",
       " (\"isn't\", 1),\n",
       " ('All', 1),\n",
       " ('Internet', 1),\n",
       " ('tend', 1),\n",
       " ('predefined', 1),\n",
       " ('chunks', 1),\n",
       " ('generator', 1),\n",
       " ('Internet.', 1),\n",
       " ('200', 1),\n",
       " ('combined', 1),\n",
       " ('sentence', 1),\n",
       " ('structures,', 1),\n",
       " ('reasonable.', 1),\n",
       " ('therefore', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd=rdd_ds.flatMap(lambda word:word.split(' '))\n",
    "freq_words=word_rdd.map(lambda word:(word,1))\n",
    "freq_words.reduceByKey(lambda a,b: a+b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a program to convert all words in a file to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"LOREM IPSUM IS SIMPLY DUMMY TEXT OF THE PRINTING AND TYPESETTING INDUSTRY. LOREM IPSUM HAS BEEN THE INDUSTRY'S STANDARD DUMMY TEXT EVER SINCE THE 1500S, WHEN AN UNKNOWN PRINTER TOOK A GALLEY OF TYPE AND SCRAMBLED IT TO MAKE A TYPE SPECIMEN BOOK. IT HAS SURVIVED NOT ONLY FIVE CENTURIES, BUT ALSO THE LEAP INTO ELECTRONIC TYPESETTING, REMAINING ESSENTIALLY UNCHANGED. IT WAS POPULARISED IN THE 1960S WITH THE RELEASE OF LETRASET SHEETS CONTAINING LOREM IPSUM PASSAGES, AND MORE RECENTLY WITH DESKTOP PUBLISHING SOFTWARE LIKE ALDUS PAGEMAKER INCLUDING VERSIONS OF LOREM IPSUM.\",\n",
       " 'CONTRARY TO POPULAR BELIEF, LOREM IPSUM IS NOT SIMPLY RANDOM TEXT. IT HAS ROOTS IN A PIECE OF CLASSICAL LATIN LITERATURE FROM 45 BC, MAKING IT OVER 2000 YEARS OLD. RICHARD MCCLINTOCK, A LATIN PROFESSOR AT HAMPDEN-SYDNEY COLLEGE IN VIRGINIA, LOOKED UP ONE OF THE MORE OBSCURE LATIN WORDS, CONSECTETUR, FROM A LOREM IPSUM PASSAGE, AND GOING THROUGH THE CITES OF THE WORD IN CLASSICAL LITERATURE, DISCOVERED THE UNDOUBTABLE SOURCE. LOREM IPSUM COMES FROM SECTIONS 1.10.32 AND 1.10.33 OF \"DE FINIBUS BONORUM ET MALORUM\" (THE EXTREMES OF GOOD AND EVIL) BY CICERO, WRITTEN IN 45 BC. THIS BOOK IS A TREATISE ON THE THEORY OF ETHICS, VERY POPULAR DURING THE RENAISSANCE. THE FIRST LINE OF LOREM IPSUM, \"LOREM IPSUM DOLOR SIT AMET..\", COMES FROM A LINE IN SECTION 1.10.32.',\n",
       " '',\n",
       " 'THE STANDARD CHUNK OF LOREM IPSUM USED SINCE THE 1500S IS REPRODUCED BELOW FOR THOSE INTERESTED. SECTIONS 1.10.32 AND 1.10.33 FROM \"DE FINIBUS BONORUM ET MALORUM\" BY CICERO ARE ALSO REPRODUCED IN THEIR EXACT ORIGINAL FORM, ACCOMPANIED BY ENGLISH VERSIONS FROM THE 1914 TRANSLATION BY H. RACKHAM.',\n",
       " 'CONTRARY TO POPULAR BELIEF, LOREM IPSUM IS NOT SIMPLY RANDOM TEXT. IT HAS ROOTS IN A PIECE OF CLASSICAL LATIN LITERATURE FROM 45 BC, MAKING IT OVER 2000 YEARS OLD. RICHARD MCCLINTOCK, A LATIN PROFESSOR AT HAMPDEN-SYDNEY COLLEGE IN VIRGINIA, LOOKED UP ONE OF THE MORE OBSCURE LATIN WORDS, CONSECTETUR, FROM A LOREM IPSUM PASSAGE, AND GOING THROUGH THE CITES OF THE WORD IN CLASSICAL LITERATURE, DISCOVERED THE UNDOUBTABLE SOURCE. LOREM IPSUM COMES FROM SECTIONS 1.10.32 AND 1.10.33 OF \"DE FINIBUS BONORUM ET MALORUM\" (THE EXTREMES OF GOOD AND EVIL) BY CICERO, WRITTEN IN 45 BC. THIS BOOK IS A TREATISE ON THE THEORY OF ETHICS, VERY POPULAR DURING THE RENAISSANCE. THE FIRST LINE OF LOREM IPSUM, \"LOREM IPSUM DOLOR SIT AMET..\", COMES FROM A LINE IN SECTION 1.10.32.',\n",
       " '',\n",
       " 'THE STANDARD CHUNK OF LOREM IPSUM USED SINCE THE 1500S IS REPRODUCED BELOW FOR THOSE INTERESTED. SECTIONS 1.10.32 AND 1.10.33 FROM \"DE FINIBUS BONORUM ET MALORUM\" BY CICERO ARE ALSO REPRODUCED IN THEIR EXACT ORIGINAL FORM, ACCOMPANIED BY ENGLISH VERSIONS FROM THE 1914 TRANSLATION BY H. RACKHAM.',\n",
       " \"THERE ARE MANY VARIATIONS OF PASSAGES OF LOREM IPSUM AVAILABLE, BUT THE MAJORITY HAVE SUFFERED ALTERATION IN SOME FORM, BY INJECTED HUMOUR, OR RANDOMISED WORDS WHICH DON'T LOOK EVEN SLIGHTLY BELIEVABLE. IF YOU ARE GOING TO USE A PASSAGE OF LOREM IPSUM, YOU NEED TO BE SURE THERE ISN'T ANYTHING EMBARRASSING HIDDEN IN THE MIDDLE OF TEXT. ALL THE LOREM IPSUM GENERATORS ON THE INTERNET TEND TO REPEAT PREDEFINED CHUNKS AS NECESSARY, MAKING THIS THE FIRST TRUE GENERATOR ON THE INTERNET. IT USES A DICTIONARY OF OVER 200 LATIN WORDS, COMBINED WITH A HANDFUL OF MODEL SENTENCE STRUCTURES, TO GENERATE LOREM IPSUM WHICH LOOKS REASONABLE. THE GENERATED LOREM IPSUM IS THEREFORE ALWAYS FREE FROM REPETITION, INJECTED HUMOUR, OR NON-CHARACTERISTIC WORDS ETC.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper=rdd_ds.map(lambda word:word.upper())\n",
    "upper.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\tWrite a program to convert all words in a file to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum.\",\n",
       " 'contrary to popular belief, lorem ipsum is not simply random text. it has roots in a piece of classical latin literature from 45 bc, making it over 2000 years old. richard mcclintock, a latin professor at hampden-sydney college in virginia, looked up one of the more obscure latin words, consectetur, from a lorem ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. lorem ipsum comes from sections 1.10.32 and 1.10.33 of \"de finibus bonorum et malorum\" (the extremes of good and evil) by cicero, written in 45 bc. this book is a treatise on the theory of ethics, very popular during the renaissance. the first line of lorem ipsum, \"lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32.',\n",
       " '',\n",
       " 'the standard chunk of lorem ipsum used since the 1500s is reproduced below for those interested. sections 1.10.32 and 1.10.33 from \"de finibus bonorum et malorum\" by cicero are also reproduced in their exact original form, accompanied by english versions from the 1914 translation by h. rackham.',\n",
       " 'contrary to popular belief, lorem ipsum is not simply random text. it has roots in a piece of classical latin literature from 45 bc, making it over 2000 years old. richard mcclintock, a latin professor at hampden-sydney college in virginia, looked up one of the more obscure latin words, consectetur, from a lorem ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. lorem ipsum comes from sections 1.10.32 and 1.10.33 of \"de finibus bonorum et malorum\" (the extremes of good and evil) by cicero, written in 45 bc. this book is a treatise on the theory of ethics, very popular during the renaissance. the first line of lorem ipsum, \"lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32.',\n",
       " '',\n",
       " 'the standard chunk of lorem ipsum used since the 1500s is reproduced below for those interested. sections 1.10.32 and 1.10.33 from \"de finibus bonorum et malorum\" by cicero are also reproduced in their exact original form, accompanied by english versions from the 1914 translation by h. rackham.',\n",
       " \"there are many variations of passages of lorem ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. if you are going to use a passage of lorem ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. all the lorem ipsum generators on the internet tend to repeat predefined chunks as necessary, making this the first true generator on the internet. it uses a dictionary of over 200 latin words, combined with a handful of model sentence structures, to generate lorem ipsum which looks reasonable. the generated lorem ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower=rdd_ds.map(lambda word:word.lower())\n",
    "lower.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\tWrite a program to capitalize first letter of each words in file (use string capitalize() method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lorem Ipsum Is Simply Dummy Text Of The Printing And Typesetting Industry. Lorem Ipsum Has Been The Industry\\'s Standard Dummy Text Ever Since The 1500s, When An Unknown Printer Took A Galley Of Type And Scrambled It To Make A Type Specimen Book. It Has Survived Not Only Five Centuries, But Also The Leap Into Electronic Typesetting, Remaining Essentially Unchanged. It Was Popularised In The 1960s With The Release Of Letraset Sheets Containing Lorem Ipsum Passages, And More Recently With Desktop Publishing Software Like Aldus Pagemaker Including Versions Of Lorem Ipsum. Contrary To Popular Belief, Lorem Ipsum Is Not Simply Random Text. It Has Roots In A Piece Of Classical Latin Literature From 45 Bc, Making It Over 2000 Years Old. Richard Mcclintock, A Latin Professor At Hampden-sydney College In Virginia, Looked Up One Of The More Obscure Latin Words, Consectetur, From A Lorem Ipsum Passage, And Going Through The Cites Of The Word In Classical Literature, Discovered The Undoubtable Source. Lorem Ipsum Comes From Sections 1.10.32 And 1.10.33 Of \"de Finibus Bonorum Et Malorum\" (the Extremes Of Good And Evil) By Cicero, Written In 45 Bc. This Book Is A Treatise On The Theory Of Ethics, Very Popular During The Renaissance. The First Line Of Lorem Ipsum, \"lorem Ipsum Dolor Sit Amet..\", Comes From A Line In Section 1.10.32.  The Standard Chunk Of Lorem Ipsum Used Since The 1500s Is Reproduced Below For Those Interested. Sections 1.10.32 And 1.10.33 From \"de Finibus Bonorum Et Malorum\" By Cicero Are Also Reproduced In Their Exact Original Form, Accompanied By English Versions From The 1914 Translation By H. Rackham. Contrary To Popular Belief, Lorem Ipsum Is Not Simply Random Text. It Has Roots In A Piece Of Classical Latin Literature From 45 Bc, Making It Over 2000 Years Old. Richard Mcclintock, A Latin Professor At Hampden-sydney College In Virginia, Looked Up One Of The More Obscure Latin Words, Consectetur, From A Lorem Ipsum Passage, And Going Through The Cites Of The Word In Classical Literature, Discovered The Undoubtable Source. Lorem Ipsum Comes From Sections 1.10.32 And 1.10.33 Of \"de Finibus Bonorum Et Malorum\" (the Extremes Of Good And Evil) By Cicero, Written In 45 Bc. This Book Is A Treatise On The Theory Of Ethics, Very Popular During The Renaissance. The First Line Of Lorem Ipsum, \"lorem Ipsum Dolor Sit Amet..\", Comes From A Line In Section 1.10.32.  The Standard Chunk Of Lorem Ipsum Used Since The 1500s Is Reproduced Below For Those Interested. Sections 1.10.32 And 1.10.33 From \"de Finibus Bonorum Et Malorum\" By Cicero Are Also Reproduced In Their Exact Original Form, Accompanied By English Versions From The 1914 Translation By H. Rackham. There Are Many Variations Of Passages Of Lorem Ipsum Available, But The Majority Have Suffered Alteration In Some Form, By Injected Humour, Or Randomised Words Which Don\\'t Look Even Slightly Believable. If You Are Going To Use A Passage Of Lorem Ipsum, You Need To Be Sure There Isn\\'t Anything Embarrassing Hidden In The Middle Of Text. All The Lorem Ipsum Generators On The Internet Tend To Repeat Predefined Chunks As Necessary, Making This The First True Generator On The Internet. It Uses A Dictionary Of Over 200 Latin Words, Combined With A Handful Of Model Sentence Structures, To Generate Lorem Ipsum Which Looks Reasonable. The Generated Lorem Ipsum Is Therefore Always Free From Repetition, Injected Humour, Or Non-characteristic Words Etc.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=rdd_ds.flatMap(lambda word:word.split(\" \"))\n",
    "caps=words.map(lambda cap:cap.capitalize()).collect()\n",
    "\" \".join(caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tFind the longest length of word from given set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non-characteristic'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longestWord=rdd_ds.flatMap(lambda word:word.split(\" \"))\n",
    "longestWord.map(lambda lw:(len(lw),lw)).max()[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.\tMap the Registration numbers to corresponding branch. 6000 series BDA, 9000 series HDA, 1000 series ML, 2000 series VLSI, 3000 series ES, 4000 series MSc, 5000 series CC. Given registration number, generate a key-value pair of Registration Number and Corresponding Branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('BDA', 6001), ('VLSI', 2001), ('VLSI', 2002), ('CC', 5001), ('BDA', 6002), ('HDA', 9001), ('ES', 3001), ('ES', 3002), ('MSc', 4001), ('MSc', 4002), ('CC', 5002), ('CC', 5003), ('MS', 1001), ('MS', 1002)]\n"
     ]
    }
   ],
   "source": [
    "reg_no = [6001,2001,2002,5001,6002,9001,3001,3002,4001,4002,5002,5003,1001,1002]\n",
    "context=spark.sparkContext.parallelize(reg_no,2)\n",
    "classify=context.map(lambda reg:('VLSI',reg) if reg>2000 and reg<3000 \n",
    "        else ('MS',reg) if reg>1000 and reg<2000\n",
    "        else ('ES',reg) if reg>3000 and reg<4000\n",
    "        else ('MSc',reg) if reg>4000 and reg<5000\n",
    "        else ('CC',reg) if reg>5000 and reg<6000\n",
    "        else ('BDA',reg) if reg>6000 and reg<7000\n",
    "        else ('HDA',reg))\n",
    "reg_kv = classify.collect()\n",
    "print(reg_kv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\tText file contain numbers. Numbers are separated by one white space. There is no order to store the numbers. One line may contain one or more numbers. Find the maximum, minimum, sum and mean of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rdd_nf = spark.sparkContext.textFile('numberfile.txt')\n",
    "text_rdd = rdd_nf.flatMap(lambda num : num.split(' '))\n",
    "num_rdd = text_rdd.map(lambda num : float(num))\n",
    "\n",
    "maximum = num_rdd.max()\n",
    "print(f'Maximum = {maximum}')\n",
    "\n",
    "minimum = num_rdd.min()\n",
    "print(f'Minimum = {minimum}')\n",
    "\n",
    "sum_num = num_rdd.sum()\n",
    "print(f'Sum = {sum_num}')\n",
    "\n",
    "mean = num_rdd.mean()\n",
    "print(f'Mean = {mean}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.\tA text file (citizen.txt) contains data about citizens of country. Fields (information in file) are Name, dob, Phone, email and state name. Another file contains mapping of state names to state code like Karnataka is codes as KA, TamilNadu as TN, Kerala KL etc. Compress the citizen.txt file by changing full state name to state code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Namratha', '19-03-1998', '9900224468', 'namrathanagaraj@gmail.com', 'KA'],\n",
       " ['Fareen', '21-08-1998', '99886375278', 'fareen123@gmail.com', 'GA'],\n",
       " ['Madhuri', '02-02-1997', '9900234567', 'madhuri9898@gmail.com', 'AP'],\n",
       " ['Poornima', '03-01-1998', '89897373701', 'poornimacs@gmail.com', 'TN'],\n",
       " ['Pooja', '01-02-1999', '98345678', 'pooja@gmail.com', 'KL'],\n",
       " ['Spoorthi', '12-12-1998', '876534098', 'spoo@gmail.com', 'GJ']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citizen_data = spark.sparkContext.textFile(\"citizen.txt\")\n",
    "state_map = spark.sparkContext.textFile(\"states.txt\")\n",
    "\n",
    "citizen_rdd = citizen_data.map(lambda x:x.split(\" \")).collect()\n",
    "state_rdd= state_map.map(lambda y:y.split(\" \")).collect()\n",
    "\n",
    "for i in range(len(citizen_rdd)):\n",
    "    for j in range(len(state_rdd)):  \n",
    "        if citizen_rdd[i][4]==state_rdd[j][0]:\n",
    "            citizen_rdd[i][4]=state_rdd[j][1]\n",
    "citizen_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Karnataka': 'KA',\n",
       " 'Goa': 'GA',\n",
       " 'AndraPradesh': 'AP',\n",
       " 'TamilNadu': 'TN',\n",
       " 'Kerala': 'KL',\n",
       " 'Gujarat': 'GJ'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateKey = state_map.map(lambda word: (word.split(' ')[0], word.split(' ')[1]))\n",
    "\n",
    "stateCode = {}\n",
    "for val in stateKey.collect():\n",
    "    stateCode[val[0]] = val[1]\n",
    "    \n",
    "stateCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Namratha 19-03-1998 9900224468 namrathanagaraj@gmail.com Karnataka', 'Fareen 21-08-1998 99886375278 fareen123@gmail.com Goa', 'Madhuri 02-02-1997 9900234567 madhuri9898@gmail.com AndraPradesh', 'Poornima 03-01-1998 89897373701 poornimacs@gmail.com TamilNadu', 'Pooja 01-02-1999 98345678 pooja@gmail.com Kerala', 'Spoorthi 12-12-1998 876534098 spoo@gmail.com Gujarat']\n"
     ]
    }
   ],
   "source": [
    "State_mapKey = spark.sparkContext.broadcast(stateCode)\n",
    "print(citizen_data.collect())\n",
    "def compress(state,codes):\n",
    "    splitData = state.split(' ')  \n",
    "    print(splitData)\n",
    "    splitData[4] = codes.value.get(splitData[4])\n",
    "    newData = ' '\n",
    "    newData = newData.join(splitData)\n",
    "    \n",
    "    return newData\n",
    "    \n",
    "Citizen = citizen_data.map(lambda data: compress(data,State_mapKey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
